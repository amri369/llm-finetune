{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "sys.argv = [\n",
    "    'causal_lm_finetune.py',\n",
    "    '--model_name_or_path', 'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    '--dataset_name', 'cnn_dailymail',\n",
    "    '--dataset_config_name', '3.0.0',\n",
    "    '--source_prefix', 'Summarize: ',\n",
    "    '--output_dir', './mistral-summarization',\n",
    "    '--do_train',\n",
    "    '--do_eval',\n",
    "    \n",
    "    '--use_lora', 'True',\n",
    "    '--lora_r', '32',\n",
    "    '--lora_alpha', '64',\n",
    "    '--lora_dropout', '0.05',\n",
    "    \n",
    "    '--per_device_train_batch_size', '4',\n",
    "    '--per_device_eval_batch_size', '4',\n",
    "    '--gradient_accumulation_steps', '4',\n",
    "    \n",
    "    '--num_train_epochs', '3',\n",
    "    '--learning_rate', '2e-5',\n",
    "    '--lr_scheduler_type', 'cosine',\n",
    "    '--warmup_ratio', '0.03',\n",
    "\n",
    "    '--max_train_samples', '5000',\n",
    "    '--max_eval_samples', '200', \n",
    "    '--max_source_length', '500',\n",
    "    '--max_target_length', '200',\n",
    "    \n",
    "    '--save_strategy', 'steps',\n",
    "    '--save_steps', '500',\n",
    "    '--eval_strategy', 'steps',\n",
    "    '--eval_steps', '25',\n",
    "    '--logging_steps', '25',\n",
    "    '--load_best_model_at_end', 'True',\n",
    "    '--metric_for_best_model', 'eval_loss',\n",
    "    \n",
    "    '--gradient_checkpointing', 'True',\n",
    "    '--max_grad_norm', '0.3',\n",
    "\n",
    "    '--overwrite_output_dir'\n",
    "]\n",
    "\n",
    "from train_summarization_causal_ml import main\n",
    "results = main()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "sys.argv = [\n",
    "    'train_summarization_causal_ml.py',\n",
    "    '--model_name_or_path', 'mistral-summarization/checkpoint-939',  # Your checkpoint\n",
    "    '--dataset_name', 'cnn_dailymail',\n",
    "    '--dataset_config_name', '3.0.0',\n",
    "    '--source_prefix', 'Summarize: ',\n",
    "    '--output_dir', './test-results',\n",
    "    '--do_predict',\n",
    "    '--per_device_eval_batch_size', '4',\n",
    "    '--max_source_length', '512',\n",
    "    '--max_target_length', '128',\n",
    "    '--max_predict_samples', '25',\n",
    "]\n",
    "\n",
    "from train_summarization_causal_ml import main\n",
    "results = main()"
   ],
   "id": "e0b5663439d51aaa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
