{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Mistral-7B-Instruct-v0.1 with LoRA\n",
    "sys.argv = [\n",
    "    'causal_lm_finetune.py',\n",
    "    '--model_name_or_path', 'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    '--dataset_name', 'cnn_dailymail',\n",
    "    '--dataset_config_name', '3.0.0',\n",
    "    '--source_prefix', 'Summarize: ',\n",
    "    '--output_dir', './mistral-summarization',\n",
    "    '--do_train',\n",
    "    '--do_eval',\n",
    "    '--use_lora', 'True',  # Enable LoRA\n",
    "    '--lora_r', '8',  # LoRA rank\n",
    "    '--lora_alpha', '16', \n",
    "    '--lora_dropout', '0.1', \n",
    "    '--per_device_train_batch_size', '4',  # Increased from 2\n",
    "    '--per_device_eval_batch_size', '4',  # Increased from 2\n",
    "    '--gradient_accumulation_steps', '2',  # Reduced from 4\n",
    "    '--num_train_epochs', '1',\n",
    "    '--max_train_samples', '1000',\n",
    "    '--max_eval_samples', '100',\n",
    "    '--max_source_length', '512',\n",
    "    '--max_target_length', '128',\n",
    "    '--learning_rate', '2e-4',  # Increased from 2e-5 for LoRA\n",
    "    '--warmup_steps', '100',\n",
    "    '--save_strategy', 'epoch',\n",
    "    '--logging_steps', '50',\n",
    "    '--fp16',\n",
    "    '--overwrite_output_dir'\n",
    "]\n",
    "\n",
    "from train_summarization_causal_ml import main\n",
    "results = main()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "sys.argv = [\n",
    "    'train_summarization_causal_ml.py',\n",
    "    '--model_name_or_path', 'mistral_instruct_generation/checkpoint-1000',  # Your checkpoint\n",
    "    '--dataset_name', 'cnn_dailymail',\n",
    "    '--dataset_config_name', '3.0.0',\n",
    "    '--source_prefix', 'Summarize: ',\n",
    "    '--output_dir', './test-results',\n",
    "    '--do_predict',\n",
    "    '--per_device_eval_batch_size', '4',\n",
    "    '--max_source_length', '512',\n",
    "    '--max_target_length', '128',\n",
    "    '--max_predict_samples', '25',\n",
    "    '--use_lora', 'True',  # If you trained with LoRA\n",
    "    '--fp16',  # Match training settings\n",
    "]\n",
    "\n",
    "from train_summarization_causal_ml import main\n",
    "results = main()"
   ],
   "id": "e0b5663439d51aaa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
